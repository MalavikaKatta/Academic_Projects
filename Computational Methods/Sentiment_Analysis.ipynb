{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MalavikaKatta/Academic_Projects/blob/main/Computational%20Methods/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Topic Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(30 points). This question is designed to help you develop a feel for the way topic modeling works, the connection to the human meanings of documents. Based on the dataset from assignment three, write a python program to **identify the top 10 topics in the dataset**. Before answering this question, please review the materials in lesson 8, especially the code for LDA, LSA, and BERTopic. The following information should be reported:\n",
        "\n",
        "(1) Features (text representation) used for topic modeling.\n",
        "\n",
        "(2) Top 10 clusters for topic modeling.\n",
        "\n",
        "(3) Summarize and describe the topic for each cluster.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating Dictionary and Document-Term Matrix"
      ],
      "metadata": {
        "id": "9eHFHXr6vaw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim import corpora\n",
        "\n",
        "# Load the annotated dataset from assignment 3\n",
        "df = pd.read_csv(\"/content/annotated_dataset (1).csv\")\n",
        "\n",
        "# Tokenize the text\n",
        "tokenized_text = [text.split() for text in df['Cleaned_Review']]\n",
        "\n",
        "# Create a Dictionary\n",
        "dictionary = corpora.Dictionary(tokenized_text)\n",
        "\n",
        "# Create a Document-Term Matrix\n",
        "doc_term_matrix = [dictionary.doc2bow(tokens) for tokens in tokenized_text]"
      ],
      "metadata": {
        "id": "3nLpyQ9TrpNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training LDA Model and Assigning Topics"
      ],
      "metadata": {
        "id": "egbqeAA8vgb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import LdaModel\n",
        "\n",
        "# Train the LDA model\n",
        "num_topics = 10  # You can adjust the number of topics\n",
        "lda_model = LdaModel(doc_term_matrix, num_topics=num_topics, id2word=dictionary, passes=15)\n",
        "\n",
        "# Display the top words for each topic\n",
        "top_words_per_topic = []\n",
        "for i in range(num_topics):\n",
        "    topic_words = [word for word, _ in lda_model.show_topic(i, topn=10)]\n",
        "    top_words_per_topic.append(topic_words)\n",
        "    print(f\"\\nTopic {i + 1}: {', '.join(topic_words)}\")\n",
        "\n",
        "# Assign topics to documents\n",
        "df['topic'] = [max(lda_model.get_document_topics(doc), key=lambda x: x[1])[0] for doc in doc_term_matrix]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_G2kQmcrpXj",
        "outputId": "f404632c-fe79-4973-9803-d7652d195758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topic 1: film, watch, would, minut, danc, need, total, two, time, also\n",
            "\n",
            "Topic 2: movi, action, one, block, like, real, song, guess, top, half\n",
            "\n",
            "Topic 3: movi, watch, rrr, action, much, one, film, like, lot, never\n",
            "\n",
            "Topic 4: movi, action, good, stori, rrr, make, charact, great, way, feel\n",
            "\n",
            "Topic 5: rrr, film, bahubali, rajamouli, mass, make, look, that, two, mind\n",
            "\n",
            "Topic 6: movi, scene, hero, well, action, stori, everyth, modern, cgi, look\n",
            "\n",
            "Topic 7: film, say, day, im, thing, visual, even, seen, know, one\n",
            "\n",
            "Topic 8: movi, see, ive, work, seen, rrr, great, use, get, fighter\n",
            "\n",
            "Topic 9: film, movi, indian, rrr, watch, action, scene, one, critic, tollywood\n",
            "\n",
            "Topic 10: seem, rajamouli, one, bheem, also, manag, film, charan, there, might\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Summarize the Clusters into topic modeling file"
      ],
      "metadata": {
        "id": "-IdqwoL5vokS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the top clusters and summarize topics\n",
        "top_clusters = df['topic'].value_counts().head(10)\n",
        "for cluster, count in top_clusters.items():\n",
        "    print(f\"\\nCluster {cluster + 1}:\")\n",
        "    print(f\"Number of Documents: {count}\")\n",
        "    print(f\"Top Words: {', '.join(top_words_per_topic[cluster])}\")\n",
        "    print(\"--------\")\n",
        "\n",
        "# Save the results to a CSV file\n",
        "df.to_csv(\"topic_modeling_results.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f02apw7Erphb",
        "outputId": "95cf55a3-f78e-4130-8fbf-713394beb0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cluster 9:\n",
            "Number of Documents: 2000\n",
            "Top Words: film, movi, indian, rrr, watch, action, scene, one, critic, tollywood\n",
            "--------\n",
            "\n",
            "Cluster 3:\n",
            "Number of Documents: 1200\n",
            "Top Words: movi, watch, rrr, action, much, one, film, like, lot, never\n",
            "--------\n",
            "\n",
            "Cluster 1:\n",
            "Number of Documents: 1200\n",
            "Top Words: film, watch, would, minut, danc, need, total, two, time, also\n",
            "--------\n",
            "\n",
            "Cluster 6:\n",
            "Number of Documents: 1200\n",
            "Top Words: movi, scene, hero, well, action, stori, everyth, modern, cgi, look\n",
            "--------\n",
            "\n",
            "Cluster 8:\n",
            "Number of Documents: 800\n",
            "Top Words: movi, see, ive, work, seen, rrr, great, use, get, fighter\n",
            "--------\n",
            "\n",
            "Cluster 4:\n",
            "Number of Documents: 800\n",
            "Top Words: movi, action, good, stori, rrr, make, charact, great, way, feel\n",
            "--------\n",
            "\n",
            "Cluster 7:\n",
            "Number of Documents: 800\n",
            "Top Words: film, say, day, im, thing, visual, even, seen, know, one\n",
            "--------\n",
            "\n",
            "Cluster 2:\n",
            "Number of Documents: 800\n",
            "Top Words: movi, action, one, block, like, real, song, guess, top, half\n",
            "--------\n",
            "\n",
            "Cluster 5:\n",
            "Number of Documents: 800\n",
            "Top Words: rrr, film, bahubali, rajamouli, mass, make, look, that, two, mind\n",
            "--------\n",
            "\n",
            "Cluster 10:\n",
            "Number of Documents: 400\n",
            "Top Words: seem, rajamouli, one, bheem, also, manag, film, charan, there, might\n",
            "--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.  \n",
        "\n",
        "(1) Features used for sentiment classification and explain why you select these features.\n",
        "\n",
        "(2) Select two of the supervised learning algorithm from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build a sentiment classifier respectively. Note: Cross-validation (5-fold or 10-fold) should be conducted. Here is the reference of cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html.\n",
        "\n",
        "(3) Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Features for Sentiment Classification"
      ],
      "metadata": {
        "id": "6M2oM2YSwgp0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vATjQNTY8buA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "992521ea-a338-4393-a169-9acc01e7e131"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TF-IDF_vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the annotated dataset from Assignment 3\n",
        "df = pd.read_csv(\"/content/annotated_dataset (1).csv\")\n",
        "\n",
        "# Features: TF-IDF representation of the cleaned reviews\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "X = tfidf_vectorizer.fit_transform(df['Cleaned_Review'])\n",
        "\n",
        "# Target: Sentiment labels (positive, negative, neutral)\n",
        "y = df['sentiment']\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Save the TF-IDF vectorizer for later use\n",
        "import joblib\n",
        "joblib.dump(tfidf_vectorizer, 'TF-IDF_vectorizer.pkl')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Building Sentiment Classifiers\n",
        "####SVM"
      ],
      "metadata": {
        "id": "hTkIECk3wxoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Build an SVM classifier\n",
        "svm_classifier = SVC(kernel='linear', C=1)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Cross-validation (5-fold)\n",
        "cv_scores_svm = cross_val_score(svm_classifier, X_train, y_train, cv=5)\n",
        "\n",
        "# Evaluate performance on the test set\n",
        "y_pred_svm = svm_classifier.predict(X_test)\n",
        "report_svm = classification_report(y_test, y_pred_svm)\n",
        "\n",
        "# Print cross-validation scores and classification report for SVM\n",
        "print(\"SVM Cross-Validation Scores:\", cv_scores_svm)\n",
        "print(\"\\nSVM Classification Report:\\n\", report_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv2axKXBwx6q",
        "outputId": "5d942f14-6f8b-4c4d-ba2a-52ffff12fa30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Cross-Validation Scores: [1. 1. 1. 1. 1.]\n",
            "\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00       250\n",
            "    positive       1.00      1.00      1.00      1750\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       1.00      1.00      1.00      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Random Forest"
      ],
      "metadata": {
        "id": "-iTx220cxO8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Build a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Cross-validation (5-fold)\n",
        "cv_scores_rf = cross_val_score(rf_classifier, X_train, y_train, cv=5)\n",
        "\n",
        "# Evaluate performance on the test set\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "report_rf = classification_report(y_test, y_pred_rf)\n",
        "\n",
        "# Print cross-validation scores and classification report for Random Forest\n",
        "print(\"Random Forest Cross-Validation Scores:\", cv_scores_rf)\n",
        "print(\"\\nRandom Forest Classification Report:\\n\", report_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5YrDpAZxTQu",
        "outputId": "ee59a4b4-1a90-482d-fb18-a44021dd97a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Cross-Validation Scores: [1. 1. 1. 1. 1.]\n",
            "\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00       250\n",
            "    positive       1.00      1.00      1.00      1750\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       1.00      1.00      1.00      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparison of SVM and Random Forest\n",
        "##Support Vector Machine (SVM) Metrics:\n",
        "###Cross-Validation Scores: [1. 1. 1. 1. 1.]\n",
        "#####Accuracy: 1.00\n",
        "#####Precision (positive): 1.00\n",
        "#####Recall (positive): 1.00\n",
        "#####F1-score (positive): 1.00\n",
        "##Random Forest Metrics:\n",
        "###Cross-Validation Scores: [1. 1. 1. 1. 1.]\n",
        "#####Accuracy: 1.00\n",
        "#####Precision (positive): 1.00\n",
        "#####Recall (positive): 1.00\n",
        "#####F1-score (positive): 1.00\n",
        "##Comparison:\n",
        "#####Accuracy: Both models achieved 100% accuracy on the dataset.\n",
        "#####Precision: Both models achieved a precision of 1.00 for the positive class, indicating no false positives.\n",
        "#####Recall: Both models achieved a recall of 1.00 for the positive class, indicating no false negatives.\n",
        "#####F1-score: Both models achieved an F1-score of 1.00 for the positive class, indicating a perfect balance between precision and recall.\n",
        "##Conclusion:\n",
        "#####Both the Support Vector Machine and Random Forest models perform exceptionally well on the provided dataset, achieving perfect scores across all evaluated metrics."
      ],
      "metadata": {
        "id": "8jsqr_AnyYhd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: House price prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(40 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download from canvas. Here is an axample for implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In this dataset, the target variable is \"SalePrice\""
      ],
      "metadata": {
        "id": "HFjA1efl1jeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Separate features and target variable\n",
        "X = train_data.drop('SalePrice', axis=1)\n",
        "y = train_data['SalePrice']\n",
        "\n",
        "# Identify numerical and categorical features\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Create preprocessing pipelines for numerical and categorical features\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine transformers into a preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create the model pipeline\n",
        "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('regressor', RandomForestRegressor(random_state=42))])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on the validation set\n",
        "valid_preds = model.predict(X_valid)\n",
        "\n",
        "# Evaluate the model\n",
        "rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
        "print(f'Root Mean Squared Error on the validation set: {rmse}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsoST4VZ4mzg",
        "outputId": "4c2439ef-5cc8-47ee-bc53-d9bbc4e1f9b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error on the validation set: 28561.708782396403\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}